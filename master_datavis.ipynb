{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook used to grab saved results from s3 and calculate properties of resulting rotation posets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SuperStableMatchingInstance\n",
    "import boto3\n",
    "import util\n",
    "import generate_prefs_with_indifference\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import GraphVisualization\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "import sage.all\n",
    "from sage.all import graphs\n",
    "from sage.graphs.graph_decompositions.vertex_separation import path_decomposition\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='AKIAQDMNJBPUYAXSPZPM',\n",
    "    aws_secret_access_key='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',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "my_bucket = s3.Bucket(\"lambda-test5\")\n",
    "def get_obj(filename):\n",
    "    bucket_name = \"lambda-test5\"\n",
    "    s3 = session.resource('s3')\n",
    "    obj = s3.Object(bucket_name, filename)\n",
    "    lines = obj.get()['Body'].read()\n",
    "    lines = str(lines)\n",
    "\n",
    "    a = lines.replace('(', '[')\n",
    "    a = a.replace(')', ']')\n",
    "    a = a.replace ('\\'', '')\n",
    "    a = a.replace ('b', '')\n",
    "    return json.loads(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keys to be grabbed\n",
    "keys = [ob.key for ob in my_bucket.objects.all() if ob.key.startswith('m/results/')]\n",
    "keys = [k for k in keys if not k.startswith('m/results/uniform')]\n",
    "uniform_keys = [ob.key for ob in my_bucket.objects.all() if ob.key.startswith('m/results/uniform')]\n",
    "uniform_keys = [k for k in uniform_keys if not k.startswith('m/results/uniform2')]\n",
    "\n",
    "# keys =['m/results/250_5_100_ind:1']\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines necessary functions, grabs all results for standard non-tiered two sided instances\n",
    "def get_all_children(edge, children):\n",
    "    children[edge[0]].append(edge[1])\n",
    "    children[edge[0]] = children[edge[0]] + children[edge[1]]\n",
    "\n",
    "\n",
    "def transitive_reduction(edges):\n",
    "    #sort edges highest to lowest by first value, lowest to highest by second. Ensures that redundant edges are added after their redundancy is exposed\n",
    "    edges = [(edge[0], -edge[1]) for edge in edges] \n",
    "    edges.sort(reverse=True)\n",
    "    edges = [(edge[0], -edge[1]) for edge in edges]\n",
    "    children = defaultdict(list)\n",
    "    to_remove = []\n",
    "    for i in range(len(edges)):\n",
    "        edge = edges[i]\n",
    "        if edge[1] in children[edge[0]]:\n",
    "            to_remove.append(i)\n",
    "        else:\n",
    "            get_all_children(edge, children)\n",
    "    to_remove.reverse()\n",
    "#     print(children)\n",
    "    for i in to_remove:\n",
    "        del edges[i]\n",
    "    return edges\n",
    "\n",
    "\n",
    "def make_df(labels):\n",
    "    df = pd.DataFrame(labels, columns=['n','k'])\n",
    "    return df\n",
    "\n",
    "def get_num_matches(rotations, matchings, label):\n",
    "    number_matches = np.zeros(100)\n",
    "\n",
    "    for i in range(len(matchings)):\n",
    "        number_matches= np.array([len(m) for m in matchings])\n",
    "        \n",
    "    number_rotations = np.zeros(100)\n",
    "\n",
    "    for i in range(len(rotations)):\n",
    "        number_rotations= np.array([len(m) for m in rotations])\n",
    "    \n",
    "    df = pd.DataFrame(number_matches, columns=['num_matches'])\n",
    "    df['num_rotations'] = number_rotations\n",
    "    df['n'] = label[0]\n",
    "    df['k'] = label[1]\n",
    "\n",
    "    return df\n",
    "        \n",
    "# def get_num_matches(matchings):\n",
    "#     number_matches = np.zeros((len(matchings), 100))\n",
    "#     for i in range(len(matchings)):\n",
    "#         number_matches[i] = np.array([len(m) for m in matchings[i]])\n",
    "#     return number_matches\n",
    "def get_rotation_poset_height(poset_edges):\n",
    "    height = np.zeros((len(poset_edges), 100))\n",
    "    for i in range(len(poset_edges)):\n",
    "        height[i] = np.array([len(m) for m in poset_edges[i]])\n",
    "    return height\n",
    "#returns the size of largest antichain and the maximum height of the poset\n",
    "def get_poset_data(num_nodes, edges):\n",
    "    edges = transitive_reduction(edges)\n",
    "    graph = graphs.EmptyGraph()\n",
    "    graph.add_edges(edges)\n",
    "    rotation_digraph = nx.DiGraph()\n",
    "    rotation_digraph.add_edges_from(edges)\n",
    "#     rotation_digraph.add_nodes_from(range(num_nodes))\n",
    "\n",
    "    pw, L = path_decomposition(graph, algorithm = \"BAB\")\n",
    "\n",
    "    max_height = nx.dag_longest_path(rotation_digraph)\n",
    "    if len(max_height) == 0 and num_nodes >= 1:\n",
    "        max_height = 1\n",
    "    else:\n",
    "        max_height = len(max_height)\n",
    "#     for c in nx.connected_components(rotation_digraph):\n",
    "#         print(c)\n",
    "#     print(n)\n",
    "    single_nodes = [n for n in range(num_nodes) if n not in rotation_digraph.nodes]\n",
    "    antichains = list(nx.algorithms.dag.antichains(rotation_digraph))\n",
    "    return max(len(a) for a in antichains)+len(single_nodes), max_height, pw\n",
    "    \n",
    "        \n",
    "def add_poset_data(matchings, rotations, poset_edges):\n",
    "    height = np.zeros((len(matchings), 100))\n",
    "    big_chain = np.zeros((len(matchings), 100))\n",
    "    pathwidth = np.zeros((len(matchings), 100))\n",
    "    for i in range(len(matchings)):\n",
    "        for j in range(len(matchings[i])):\n",
    "            big_chain[i][j], height[i][j], pathwidth[i][j] = get_poset_data(len(rotations[i][j]),(poset_edges[i][j]))\n",
    "    return height, big_chain, pathwidth\n",
    "\n",
    "\n",
    "\n",
    "def create_df_end_to_end(keys):\n",
    "    matchings = []\n",
    "    rotations = []\n",
    "    poset_edges = []\n",
    "    labels = []\n",
    "    j = 0\n",
    "    for i in range(len(keys)):\n",
    "        info =  keys[i].split('_')\n",
    "        if len(info) == 3:\n",
    "            _, k, count = info\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            n, k, count, ind = info\n",
    "            n = n.split('/')[-1]\n",
    "            if ind[0]!= 'i': #if nonzero indifference\n",
    "                labels.append((n, int(k), 1))\n",
    "            else:\n",
    "                labels.append((n, int(k), float(ind[4:])))\n",
    "        print(labels[i])\n",
    "        matchings.append([])\n",
    "        rotations.append([])\n",
    "        poset_edges.append([])\n",
    "        for run in get_obj(keys[i]):\n",
    "            matchings[j].append(run[0])\n",
    "            rotations[j].append(run[1])\n",
    "            poset_edges[j].append(run[2])\n",
    "        j+=1\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # num_matches = get_num_matches(matchings)\n",
    "    # num_rotations = get_num_matches(rotations)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i])\n",
    "        df = pd.concat([df, get_num_matches(rotations[i], matchings[i], labels[i])], ignore_index = True)\n",
    "    #     df = pd.concat([df, get_num_matches(rotations[i], labels[i])], ignore_index = True)\n",
    "    height, max_antichain, pathwidth = add_poset_data(matchings, rotations, poset_edges)\n",
    "    \n",
    "    dft2 = pd.DataFrame()\n",
    "    for i in range(len(labels)):\n",
    "        dft = pd.DataFrame(height[i], columns = ['height'])\n",
    "        dft['max_antichain'] = max_antichain[i]\n",
    "        dft['pathwidth'] = pathwidth[i]\n",
    "        dft['indifference'] = labels[i][2]\n",
    "\n",
    "        dft2 = pd.concat([dft2, dft], ignore_index=True)\n",
    "        \n",
    "    df['indifference'] = dft2['indifference']\n",
    "    df['height'] = dft2['height']\n",
    "    df['max_antichain'] = dft2['max_antichain']\n",
    "    df['pathwidth'] = dft2['pathwidth']\n",
    "    df['n'] = df['n'].astype(int)\n",
    "\n",
    "        \n",
    "    return df\n",
    "\n",
    "df= create_df_end_to_end(keys)\n",
    "\n",
    "if 'k' in df.columns:\n",
    "    df['tier_size/k'] = df['k'].astype(int)\n",
    "    df = df.drop('k', axis=1)\n",
    "df['tiered'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the transitive reduction function\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_all_children(edge, children):\n",
    "    children[edge[0]].append(edge[1])\n",
    "    children[edge[0]] = children[edge[0]] + children[edge[1]]\n",
    "\n",
    "def transitive_reduction(edges):\n",
    "    #sort edges highest to lowest by first value, lowest to highest by second. Ensures that redundant edges are added after their redundancy is exposed\n",
    "    edges = [(edge[0], -edge[1]) for edge in edges] \n",
    "    edges.sort(reverse=True)\n",
    "    edges = [(edge[0], -edge[1]) for edge in edges]\n",
    "    children = defaultdict(list)\n",
    "    to_remove = []\n",
    "    for i in range(len(edges)):\n",
    "        edge = edges[i]\n",
    "        if edge[1] in children[edge[0]]:\n",
    "            to_remove.append(i)\n",
    "        else:\n",
    "            get_all_children(edge, children)\n",
    "\n",
    "    to_remove.reverse()\n",
    "    for i in to_remove:\n",
    "        del edges[i]\n",
    "    return edges\n",
    "edges = [[0, 24], [0, 18], [0, 8], [0, 15], [0, 22], [0, 12], [0, 3], [0, 23], [1, 11], [1, 12], [1, 21], [1, 26], [1, 16], [1, 10], [1, 3], [1, 20], [1, 25], [1, 14], [1, 23], [1, 9], [1, 18], [1, 24], [1, 22], [1, 27], [1, 8], [2, 18], [2, 8], [2, 3], [2, 26], [2, 10], [2, 21], [2, 15], [3, 24], [3, 23], [3, 12], [3, 18], [3, 11], [3, 6], [3, 5], [3, 22], [3, 15], [3, 21], [3, 10], [3, 9], [3, 26], [3, 4], [3, 25], [3, 14], [3, 19], [3, 8], [4, 10], [4, 15], [4, 28], [4, 8], [4, 22], [4, 23], [5, 8], [5, 21], [5, 10], [6, 9], [6, 7], [6, 10], [6, 23], [6, 27], [6, 15], [6, 18], [6, 8], [6, 12], [7, 12], [7, 25], [7, 8], [7, 21], [7, 18], [7, 11], [7, 23], [8, 15], [8, 21], [8, 12], [8, 18], [8, 9], [8, 25], [8, 22], [8, 13], [8, 19], [8, 10], [8, 26], [8, 23], [8, 14], [8, 20], [8, 11], [8, 27], [9, 16], [9, 19], [9, 25], [9, 23], [9, 18], [9, 12], [9, 22], [9, 15], [9, 10], [10, 18], [10, 23], [10, 25], [10, 15], [10, 26], [10, 11], [10, 12], [10, 27], [10, 22], [11, 22], [11, 26], [11, 25], [11, 14], [11, 18], [11, 12], [12, 17], [12, 28], [12, 27], [12, 13], [12, 24], [12, 18], [12, 23], [12, 14], [12, 25], [12, 19], [12, 15], [12, 26], [13, 23], [13, 26], [13, 22], [13, 15], [13, 24], [14, 17], [14, 18], [14, 15], [14, 21], [14, 22], [14, 25], [14, 26], [14, 23], [14, 16], [15, 27], [15, 26], [15, 23], [15, 25], [15, 24], [15, 21], [15, 18], [15, 17], [16, 25], [16, 17], [17, 26], [18, 19], [18, 25], [18, 26], [18, 22], [18, 27], [18, 23], [19, 22], [19, 21], [19, 20], [20, 27], [20, 22], [20, 23], [22, 25], [22, 23], [22, 24], [23, 26], [23, 25], [24, 26], [25, 26], [25, 27], [26, 28]]\n",
    "\n",
    "transitive_reduction(edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('dfs/final/master_df_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabbing results for non-tiered one-sided runs\n",
    "def create_df_end_to_end_uniform(keys):\n",
    "    matchings = []\n",
    "    rotations = []\n",
    "    poset_edges = []\n",
    "    labels = []\n",
    "    j = 0\n",
    "    for i in range(len(keys)):\n",
    "        info =  keys[i].split('x')[0].split('_')\n",
    "        n, k, count, ind = info\n",
    "        n = n.split('/')[-1]\n",
    "        if ind[0]!= 'i': #if nonzero indifference\n",
    "            labels.append((n, int(k), 1))\n",
    "        else:\n",
    "            labels.append((n, int(k), float(ind[4:])))\n",
    "        print(labels[i])\n",
    "        matchings.append([])\n",
    "        rotations.append([])\n",
    "        poset_edges.append([])\n",
    "        for run in get_obj(keys[i]):\n",
    "            matchings[j].append(run[0])\n",
    "            rotations[j].append(run[1])\n",
    "            poset_edges[j].append(run[2])\n",
    "        j+=1\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # num_matches = get_num_matches(matchings)\n",
    "    # num_rotations = get_num_matches(rotations)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i])\n",
    "        df = pd.concat([df, get_num_matches(rotations[i], matchings[i], labels[i])], ignore_index = True)\n",
    "    #     df = pd.concat([df, get_num_matches(rotations[i], labels[i])], ignore_index = True)\n",
    "    height, max_antichain, pathwidth = add_poset_data(matchings, rotations, poset_edges)\n",
    "    \n",
    "    dft2 = pd.DataFrame()\n",
    "    for i in range(len(labels)):\n",
    "        dft = pd.DataFrame(height[i], columns = ['height'])\n",
    "        dft['max_antichain'] = max_antichain[i]\n",
    "        dft['pathwidth'] = pathwidth[i]\n",
    "        dft2 = pd.concat([dft2, dft], ignore_index=True)\n",
    "\n",
    "    df['height'] = dft2['height']\n",
    "    df['max_antichain'] = dft2['max_antichain']\n",
    "    df['pathwidth'] = dft2['pathwidth']\n",
    "    df['n'] = df['n'].astype(int)\n",
    "\n",
    "        \n",
    "    return df\n",
    "\n",
    "uniform_df= create_df_end_to_end_uniform(uniform_keys)\n",
    "if 'k' in uniform_df.columns:\n",
    "    uniform_df['tier_size/k'] = uniform_df['k'].astype(int)\n",
    "    uniform_df = uniform_df.drop('k', axis=1)\n",
    "uniform_df['tiered'] = 0\n",
    "uniform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabbing results for one-sided tiered runs\n",
    "uniform_keys_tiered = [ob.key for ob in my_bucket.objects.all() if ob.key.startswith('big/results/uniform/100_[')]\n",
    "def create_df_end_to_end_uniform_tiered(keys):\n",
    "    matchings = []\n",
    "    rotations = []\n",
    "    poset_edges = []\n",
    "    labels = []\n",
    "    j = 0\n",
    "    for i in range(len(keys)):\n",
    "        info =  keys[i].split('x')[0].split('_')\n",
    "        n, k, count, ind = info\n",
    "        n = n.split('/')[-1]\n",
    "        k = k.split('[')[-1]\n",
    "        k = k.split(',')\n",
    "        k=k[-1]\n",
    "        k = k.replace(']', '')\n",
    "\n",
    "        if ind[0]!= 'i': #if nonzero indifference\n",
    "            labels.append((n, int(k), 1))\n",
    "        else:\n",
    "            labels.append((n, int(k), float(ind[4:])))\n",
    "        print(labels[i])\n",
    "        matchings.append([])\n",
    "        rotations.append([])\n",
    "        poset_edges.append([])\n",
    "        for run in get_obj(keys[i]):\n",
    "            matchings[j].append(run[0])\n",
    "            rotations[j].append(run[1])\n",
    "            poset_edges[j].append(run[2])\n",
    "        j+=1\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # num_matches = get_num_matches(matchings)\n",
    "    # num_rotations = get_num_matches(rotations)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i])\n",
    "        df = pd.concat([df, get_num_matches(rotations[i], matchings[i], labels[i])], ignore_index = True)\n",
    "    #     df = pd.concat([df, get_num_matches(rotations[i], labels[i])], ignore_index = True)\n",
    "    height, max_antichain, pathwidth = add_poset_data(matchings, rotations, poset_edges)\n",
    "    \n",
    "    dft2 = pd.DataFrame()\n",
    "    for i in range(len(labels)):\n",
    "        dft = pd.DataFrame(height[i], columns = ['height'])\n",
    "        dft['max_antichain'] = max_antichain[i]\n",
    "        dft['pathwidth'] = pathwidth[i]\n",
    "        dft2 = pd.concat([dft2, dft], ignore_index=True)\n",
    "\n",
    "    df['height'] = dft2['height']\n",
    "    df['max_antichain'] = dft2['max_antichain']\n",
    "    df['pathwidth'] = dft2['pathwidth']\n",
    "    df['n'] = df['n'].astype(int)\n",
    "\n",
    "        \n",
    "    return df\n",
    "\n",
    "uniform_df_tiered= create_df_end_to_end_uniform_tiered(uniform_keys_tiered)\n",
    "if 'k' in uniform_df_tiered.columns:\n",
    "    uniform_df_tiered['tier_size/k'] = uniform_df_tiered['k'].astype(int)\n",
    "    uniform_df_tiered = uniform_df_tiered.drop('k', axis=1)\n",
    "uniform_df_tiered['tiered'] = 1\n",
    "uniform_df_tiered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_df_master = pd.concat([uniform_df, uniform_df_tiered])\n",
    "uniform_df_master.to_csv('dfs/final/master_df_uniform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for two-sided tiered runs, simulated a two-sided tiered run by doing multiple individual instances of the size k. All relevant properties for the instance are a simple function of the results of the individual instance runs. \n",
    "import random\n",
    "def run_tiered(tiers, seed):\n",
    "    random.seed(seed)\n",
    "    tier_results = []\n",
    "    num_matchings = 0\n",
    "    num_rotations = 0\n",
    "    max_height = 0\n",
    "    max_antichain = 0\n",
    "    max_pathwidth = 0\n",
    "    for tier in tiers:\n",
    "    \n",
    "        male_prefs = []\n",
    "        female_prefs = []\n",
    "        for j in range(tier):\n",
    "            a_male_prefs = list(range(tier))\n",
    "            random.shuffle(a_male_prefs)\n",
    "            a_female_prefs = list(range(tier))\n",
    "            random.shuffle(a_female_prefs)\n",
    "            male_prefs.append([[i] for i in a_male_prefs])\n",
    "            female_prefs.append([[i] for i in a_female_prefs])\n",
    "        \n",
    "        matchings, rotations, poset_edges = SuperStableMatchingInstance.run_example(male_prefs, female_prefs)\n",
    "        antichain, height, pathwidth = get_poset_data(len(rotations), poset_edges)\n",
    "        \n",
    "        max_antichain += antichain\n",
    "        max_pathwidth = max(pathwidth, max_pathwidth)\n",
    "        max_height = max(max_height, height)\n",
    "        num_rotations += len(rotations)\n",
    "        if num_matchings ==0:\n",
    "            num_matchings += len(matchings)\n",
    "        else:\n",
    "            num_matchings *= len(matchings)\n",
    "            \n",
    "            \n",
    "        \n",
    "    return num_matchings, num_rotations, max_height, max_antichain, max_pathwidth\n",
    "\n",
    "\n",
    "#simulate tiered for fixed k=5 variable n\n",
    "df_tiered = pd.DataFrame()\n",
    "for n in range(25, 251, 25):\n",
    "    print(n)\n",
    "    arr = np.zeros((100, 5))\n",
    "    for i in range(100):\n",
    "        arr[i] = run_tiered([5]*int(n/5),i)\n",
    "    temp_df = pd.DataFrame(arr, columns = ['num_matches', 'num_rotations', 'height', 'max_antichain', 'pathwidth'])\n",
    "    temp_df['k'] = 5\n",
    "    temp_df['n'] = n\n",
    "    df_tiered = pd.concat([df_tiered, temp_df])\n",
    "df_tiered['tiered'] = 1\n",
    "# df2.to_csv(\"dfs/master_tiered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate tiered for fixed n=100 variable k\n",
    "df_tiered2 = pd.DataFrame()\n",
    "for k in [5, 10, 20, 25, 50, 100]:\n",
    "    print(k)\n",
    "    arr = np.zeros((100, 5))\n",
    "    for i in range(100):\n",
    "        arr[i] = run_tiered([k]*int(100/k),i)\n",
    "    temp_df = pd.DataFrame(arr, columns = ['num_matches', 'num_rotations', 'height', 'max_antichain', 'pathwidth'])\n",
    "    temp_df['k'] = k\n",
    "    temp_df['n'] = 100\n",
    "    df_tiered2 = pd.concat([df_tiered2, temp_df])\n",
    "df_tiered2['tiered'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiered2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_df_end_to_end_tiered():\n",
    "#     keys = ['big/results/tiered//100_[100]_100']\n",
    "#     matchings = []\n",
    "#     rotations = []\n",
    "#     poset_edges = []\n",
    "#     labels = []\n",
    "#     j = 0\n",
    "#     for i in range(len(keys)):\n",
    "#         info =  keys[i].split('_')\n",
    "#         if len(info) == 3:\n",
    "            \n",
    "#             n, k, count = info\n",
    "#             n = n.split('/')[-1]\n",
    "#             labels.append((n, 100, 1))\n",
    "#         else:\n",
    "#             n, k, count, ind = info\n",
    "#             n = n.split('/')[-1]\n",
    "#             if ind[0]!= 'i': #if nonzero indifference\n",
    "#                 labels.append((n, int(k), 1))\n",
    "#             else:\n",
    "#                 labels.append((n, int(k), float(ind[4:])))\n",
    "#         print(labels[i])\n",
    "#         matchings.append([])\n",
    "#         rotations.append([])\n",
    "#         poset_edges.append([])\n",
    "#         for run in get_obj(keys[i]):\n",
    "#             matchings[j].append(run[0])\n",
    "#             rotations[j].append(run[1])\n",
    "#             poset_edges[j].append(run[2])\n",
    "#         j+=1\n",
    "\n",
    "#     df = pd.DataFrame()\n",
    "#     # num_matches = get_num_matches(matchings)\n",
    "#     # num_rotations = get_num_matches(rotations)\n",
    "\n",
    "#     for i in range(len(labels)):\n",
    "#         print(labels[i])\n",
    "#         df = pd.concat([df, get_num_matches(rotations[i], matchings[i], labels[i])], ignore_index = True)\n",
    "#     #     df = pd.concat([df, get_num_matches(rotations[i], labels[i])], ignore_index = True)\n",
    "#     height, max_antichain, pathwidth = add_poset_data(matchings, rotations, poset_edges)\n",
    "    \n",
    "#     dft2 = pd.DataFrame()\n",
    "#     for i in range(len(labels)):\n",
    "#         dft = pd.DataFrame(height[i], columns = ['height'])\n",
    "#         dft['max_antichain'] = max_antichain[i]\n",
    "#         dft['pathwidth'] = pathwidth[i]\n",
    "#         dft2 = pd.concat([dft2, dft], ignore_index=True)\n",
    "\n",
    "#     df['height'] = dft2['height']\n",
    "#     df['max_antichain'] = dft2['max_antichain']\n",
    "#     df['pathwidth'] = dft2['pathwidth']\n",
    "#     df['n'] = df['n'].astype(int)\n",
    "\n",
    "        \n",
    "#     return df\n",
    "\n",
    "# df_tiered3 = create_df_end_to_end_tiered()\n",
    "# df_tiered3['tiered'] = 1\n",
    "# df_tiered3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiered_master = pd.concat([df_tiered, df_tiered2, df_tiered3])\n",
    "df_tiered_master['tier_size/k'] = df_tiered_master['k']\n",
    "df_tiered_master = df_tiered_master.drop(['k'], axis=1)\n",
    "df_tiered_master['tiered']= 1\n",
    "df_tiered_master.to_csv('master_tiered_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots showing effect of k tiered vs k-range\n",
    "\n",
    "\n",
    "plotdf = pd.concat((df[df['indifference']==1], df_tiered_master))\n",
    "plotdf = plotdf[plotdf['n']==100]\n",
    "plt.clf()\n",
    "g = sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"num_matches\", hue='tiered', kind = \"line\")\n",
    "g.set(yscale=\"log\")\n",
    "plt.savefig('plots/tier_compare/matches.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"num_rotations\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/tier_compare/rotations.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"height\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/tier_compare/height.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"max_antichain\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/tier_compare/max_antichain.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"pathwidth\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/tier_compare/pathwidth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots showing effect of indifference\n",
    "\n",
    "plotdf = df[df['tiered']==0]\n",
    "plotdf = plotdf[plotdf['n']==100]\n",
    "\n",
    "plt.clf()\n",
    "g = sns.relplot(data=plotdf, x=\"tier_size/k\", y=\"num_matches\", hue='indifference', kind = \"line\", ci= None)\n",
    "plt.savefig('plots/indiff_analysis/matches.png')\n",
    "plt.clf()\n",
    "sns.relplot(data=plotdf, x=\"tier_size/k\", y=\"num_rotations\", hue='indifference', kind = \"line\", ci= None)\n",
    "plt.savefig('plots/indiff_analysis/rotations.png')\n",
    "plt.clf()\n",
    "sns.relplot(data=plotdf, x=\"tier_size/k\", y=\"height\", hue='indifference', kind = \"line\", ci= None)\n",
    "plt.savefig('plots/indiff_analysis/height.png')\n",
    "plt.clf()\n",
    "sns.relplot(data=plotdf, x=\"tier_size/k\", y=\"max_antichain\", hue='indifference', kind = \"line\", ci= None)\n",
    "plt.savefig('plots/indiff_analysis/max_antichain.png')\n",
    "plt.clf()\n",
    "sns.relplot(data=plotdf, x=\"tier_size/k\", y=\"pathwidth\", hue='indifference', kind = \"line\", ci= None)\n",
    "plt.savefig('plots/indiff_analysis/pathwidth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plots showing effect of raising n tiered vs k-range\n",
    "\n",
    "plotdf = pd.concat((df[df['indifference']==1], df_tiered_master))\n",
    "plotdf = plotdf[plotdf['tier_size/k']==5]\n",
    "plt.clf()\n",
    "g = sns.pointplot(data=plotdf, x=\"n\", y=\"num_matches\", hue='tiered', kind = \"line\")\n",
    "g.set(yscale=\"log\")\n",
    "plt.savefig('plots/bign/matches.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"n\", y=\"num_rotations\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/bign/rotations.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"n\", y=\"height\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/bign/height.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"n\", y=\"max_antichain\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/bign/max_antichain.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"n\", y=\"pathwidth\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/bign/pathwidth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plots comparing k-range and tiered against uniform\n",
    "\n",
    "plotdf = uniform_df_master\n",
    "plt.clf()\n",
    "g = sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"num_matches\", hue='tiered', kind = \"line\")\n",
    "g.set(yscale=\"log\")\n",
    "plt.savefig('plots/uniform/matches.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"num_rotations\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/uniform/rotations.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"height\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/uniform/height.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"max_antichain\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/uniform/max_antichain.png')\n",
    "plt.clf()\n",
    "sns.pointplot(data=plotdf, x=\"tier_size/k\", y=\"pathwidth\", hue='tiered', kind = \"line\")\n",
    "plt.savefig('plots/uniform/pathwidth.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
